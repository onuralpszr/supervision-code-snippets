{
	
	"Supervision Basic Object Detection Example": {
		"prefix": "sv.example.basic_detection",
		"body": [
			"import cv2",
			"import supervision as sv",
			"from ultralytics import YOLO",
			"",
			"# Load YOLOv8 model",
			"model = YOLO(\"${1:yolov8n.pt}\")",
			"",
			"# Load image",
			"image = cv2.imread(\"${2:path/to/image.jpg}\")",
			"",
			"# Run inference",
			"results = model(image)",
			"",
			"# Convert results to supervision format",
			"detections = sv.Detections.from_ultralytics(results[0])",
			"",
			"# Initialize annotator",
			"box_annotator = sv.BoxAnnotator()",
			"",
			"# Annotate and display the image",
			"annotated_image = box_annotator.annotate(scene=image, detections=detections)",
			"cv2.imshow(\"Supervision Detection\", annotated_image)",
			"cv2.waitKey(0)",
			"$0"
		],
		"description": "Basic object detection example using Supervision and YOLOv8"
	},
	"Supervision Video Processing": {
		"prefix": "sv.example.video_processing",
		"body": [
			"import cv2",
			"import supervision as sv",
			"from ultralytics import YOLO",
			"",
			"# Load YOLOv8 model",
			"model = YOLO(\"${1:yolov8n.pt}\")",
			"",
			"# Open video",
			"video_path = \"${2:path/to/video.mp4}\"",
			"cap = cv2.VideoCapture(video_path)",
			"",
			"# Initialize annotators",
			"box_annotator = sv.BoxAnnotator()",
			"",
			"# Process video frames",
			"while cap.isOpened():",
			"    ret, frame = cap.read()",
			"    if not ret:",
			"        break",
			"        ",
			"    # Run detection",
			"    results = model(frame)",
			"    detections = sv.Detections.from_ultralytics(results[0])",
			"    ",
			"    # Annotate frame",
			"    annotated_frame = box_annotator.annotate(scene=frame, detections=detections)",
			"    ",
			"    # Display annotated frame",
			"    cv2.imshow(\"Supervision\", annotated_frame)",
			"    ",
			"    if cv2.waitKey(1) & 0xFF == ord('q'):",
			"        break",
			"",
			"cap.release()",
			"cv2.destroyAllWindows()",
			"$0"
		],
		"description": "Process video with Supervision and YOLOv8"
	},
	"Supervision Object Tracking Example": {
		"prefix": "sv.example.object_tracking",
		"body": [
			"import cv2",
			"import supervision as sv",
			"from ultralytics import YOLO",
			"",
			"# Load YOLOv8 model",
			"model = YOLO(\"${1:yolov8n.pt}\")",
			"",
			"# Initialize ByteTrack tracker",
			"byte_tracker = sv.ByteTrack()",
			"",
			"# Initialize annotators",
			"box_annotator = sv.BoxAnnotator()",
			"trace_annotator = sv.TraceAnnotator(color=sv.ColorPalette.default(), thickness=2, trace_length=10)",
			"",
			"# Open video",
			"video_path = \"${2:path/to/video.mp4}\"",
			"cap = cv2.VideoCapture(video_path)",
			"",
			"# Process video frames",
			"while cap.isOpened():",
			"    ret, frame = cap.read()",
			"    if not ret:",
			"        break",
			"        ",
			"    # Run detection",
			"    results = model(frame)",
			"    detections = sv.Detections.from_ultralytics(results[0])",
			"    ",
			"    # Track objects",
			"    detections = byte_tracker.update_with_detections(detections)",
			"    ",
			"    # Annotate frame",
			"    annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=detections)",
			"    annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)",
			"    ",
			"    # Display annotated frame",
			"    cv2.imshow(\"Supervision Tracking\", annotated_frame)",
			"    ",
			"    if cv2.waitKey(1) & 0xFF == ord('q'):",
			"        break",
			"",
			"cap.release()",
			"cv2.destroyAllWindows()",
			"$0"
		],
		"description": "Object tracking example using Supervision's ByteTrack implementation"
	},

}
